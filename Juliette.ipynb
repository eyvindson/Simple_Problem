{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88fba40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NONE\n",
      "NONE\n",
      "WARNING: Implicitly replacing the Component attribute OBJ (type=<class\n",
      "    'pyomo.core.base.objective.ScalarObjective'>) on block unknown with a new\n",
      "    Component (type=<class 'pyomo.core.base.objective.ScalarObjective'>). This\n",
      "    is usually indicative of a modelling error. To avoid this warning, use\n",
      "    block.del_component() and block.add_component().\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division #used in Python2.x so the division btw integers result in float, default in python3\n",
    "from pyomo.environ import * #library for modeling and optimisation\n",
    "import argparse\n",
    "from pyomo.opt import SolverStatus, TerminationCondition #provide status of solvers\n",
    "import pandas as pd #data manipulation library\n",
    "import numpy as np \n",
    "import pyutilib.services\n",
    "import pickle\n",
    "import random\n",
    "import sqlite3\n",
    "import copy\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "Results_folder = \"./results/\"\n",
    "\n",
    "INTEREST = 0.03\n",
    "SCENARIOS = 1\n",
    "SALV_PRICE = 0\n",
    "    \n",
    "SALVAGE = \"\"\n",
    "\n",
    "OPT=\"_NPV\"\n",
    "\n",
    "OPT = OPT + \"_\"+str(SALV_PRICE) #QUESTION: Here OPT becomes _NPV_0 > Why do we need that?\n",
    "\n",
    "#REQUIRES CBC TO BE INSTALLED ON THE MACHINE USED!!!  See https://github.com/coin-or/Cbc -- OTHER SOLVERS CAN BE USED -- \n",
    "#THEN CHANGE this line: \"opt = SolverFactory('cbc') #Here we use the cbc solver -- open source software\"\n",
    "\n",
    "path = \"C:/Users/juhu/OneDrive - Norwegian University of Life Sciences/Documents/Python/Simple_Problem/\"#ADJUST TO OWN PATH #\"c:/mytemp/avohakkutpois/Files_for_optimization/temp/\"\n",
    "#path = \"C:/temp/GIT/Simple_Problem/\"\n",
    "\n",
    "class optimization:\n",
    "    def __init__(self):\n",
    "        #c = 0\n",
    "        # Load data and preprocess by extracting branch and id from the id column\n",
    "        data_opt =  pd.read_csv(path+\"Data_Juliette.csv\")\n",
    "        data_opt['branch'] = [int(str(i)[-2:]) for i in data_opt['id']]\n",
    "        data_opt['id'] = [int(str(i)[:-2]) for i in data_opt['id']]\n",
    "\n",
    "        for k in range(0,SCENARIOS):\n",
    "            if k == 0:\n",
    "                dat = data_opt\n",
    "                dat['iteration']=k\n",
    "        data_opt = dat\n",
    "        combinations = 1\n",
    "\n",
    "        #CREATE replicates with varying iterations\n",
    "        # Data structure initialization\n",
    "        all_data = data_opt\n",
    "\n",
    "        #Index_values = all_data.set_index(['id','branch']).index.unique() #array with unique index values composed of 'id' and 'branch'\n",
    "        all_data = all_data.set_index(['id','branch','year']) #reassigns the Df with new multi-level index\n",
    "        #AREA = all_data.loc[slice(None),0,2016,all_data.index.get_level_values(3).min()]['AREA']\n",
    "        all_data = all_data.fillna(0)\n",
    "        all_data['year'] = all_data.index.get_level_values(2)\n",
    "        self.data_opt=all_data #the preprocessing fgets embedded in the class\n",
    "\n",
    "        self.combinations = 1\n",
    "\n",
    "        #CREATE replicates with varying iterations\n",
    "\n",
    "        self.all_data = self.data_opt\n",
    "        self.Index_values = self.all_data.drop(['year'], axis=1).reset_index().set_index(['id','branch']).index.unique()#all_data.set_index(['id','branch']).index.unique()\n",
    "        self.AREA = self.all_data.loc[slice(None),0,2016]['AREA']\n",
    "        self.all_data = self.all_data.fillna(0)\n",
    "\n",
    "        self.createModel()\n",
    "\n",
    "    def createModel(self):\n",
    "        # Declare sets - These used to recongnize the number of stands, regimes and number of periods in the analysis.\n",
    "        # Define sets, variables, and constraints for the optimization problem\n",
    "        \n",
    "        self.model1 = ConcreteModel() #defining the model\n",
    "\n",
    "        self.model1.stands = Set(initialize = list(set(self.all_data.index.get_level_values(0)))) #initialized with unique values from the first level of the index created earlier\n",
    "        self.model1.year = Set(initialize = list(set(self.all_data.index.get_level_values(2)))) #initialized with unique values from the third level of the index created earlier\n",
    "        #self.model1.iteration = Set(initialize = list(set(self.all_data.index.get_level_values(3))))        \n",
    "        self.model1.regimes = Set(initialize = list(set(self.all_data.index.get_level_values(1))))\n",
    "        self.model1.scen_index = Set(initialize= [i for i in range(0,self.combinations)])\n",
    "        self.model1.Index_values = self.Index_values\n",
    "\n",
    "        # Indexes (stand, regime)-- excludes those combinations that have no regimes simulated\n",
    "\n",
    "        def index_rule(model1):\n",
    "            index = []\n",
    "            for (s,r) in model1.Index_values: #stand_set\n",
    "                index.append((s,r))\n",
    "            return index\n",
    "        self.model1.index1 = Set(dimen=2, initialize=index_rule)\n",
    "\n",
    "        #Decision variable\n",
    "        self.model1.X1 = Var(self.model1.index1, within=NonNegativeReals, bounds=(0,1), initialize=1)\n",
    "\n",
    "        self.all_data['year'] = self.all_data.index.get_level_values(2)\n",
    "\n",
    "        #objective function:\n",
    "        def outcome_rule(model1):\n",
    "            return sum((self.all_data.Harvested_V.loc[(s,r,k)]*self.all_data.AREA.loc[(s,r,k)]* self.model1.X1[(s,r)])/((1+INTEREST)**(2.5+self.all_data.year[(s,r,k)]))  for (s,r) in self.model1.index1 for k in self.model1.year)\n",
    "        self.model1.OBJ = Objective(rule=outcome_rule, sense=maximize)\n",
    "\n",
    "        #Constraint:\n",
    "        def regime_rule(model1, s):\n",
    "            row_sum = sum(model1.X1[(s,r)] for r in [x[1] for x in model1.index1 if x[0] == s])\n",
    "            return row_sum == 1\n",
    "        self.model1.regime_limit = Constraint(self.model1.stands, rule=regime_rule)\n",
    "\n",
    "    def solve(self):\n",
    "        # Specify the solver and solve the model\n",
    "        opt = SolverFactory('cbc') #Here we use the cbc solver -- open source software\n",
    "        self.results = opt.solve(self.model1,tee=False) #We solve a problem, but do not show the solver output\n",
    "\n",
    "# Create an optimization object        \n",
    "t1 = optimization()\n",
    "t2 = copy.deepcopy(t1)\n",
    "\n",
    "# Modify the optimization model to focus on. Currently maximizing the NPV.\n",
    "\n",
    "### MAX MINIMUM NPV:\n",
    "#Max min\n",
    "try:\n",
    "    t2.model1.del_component(t2.model1.NPV_INV)\n",
    "except:\n",
    "    print(\"NONE\")\n",
    "\n",
    "#A function that evaluates NPV -- this includes wind disturbed salvage (however, the data doesn't include -- so it could be simplified.)    \n",
    "t2.model1.NPV= Var(within=NonNegativeReals)\n",
    "def NPV_INVENTORY(model1):\n",
    "    row_sum = sum(((t2.all_data.income.loc[(s,r,k)]+t2.all_data.natural_rm_wind.loc[(s,r,k)]*SALV_PRICE)*t2.all_data.AREA.loc[(s,r,k)]* t2.model1.X1[(s,r)])/((1+INTEREST)**(2.5+t2.all_data.year[(s,r,k)]-2016))  for (s,r) in t2.model1.index1 for k in t2.model1.year)+sum((t2.all_data.PV.loc[(s,r,max(t2.all_data.year[(s,r,slice(None))]))]*t2.all_data.AREA.loc[(s,r,max(t2.all_data.year[(s,r,slice(None))]))]* t2.model1.X1[(s,r)])/((1+INTEREST)**(2.5+max(t2.all_data.year[(s,r,slice(None))])-2016))  for (s,r) in t2.model1.index1)\n",
    "    return t2.model1.NPV<=row_sum\n",
    "t2.model1.NPV_INV= Constraint(rule=NPV_INVENTORY)\n",
    "\n",
    "\n",
    "# #JUL:A function that evaluates the combined HSI\n",
    "# t2.model1.HSI=Var(within=NonNegativeReals, bounds=(0,1))\n",
    "# def COMBINED_HSI(model1, s):\n",
    "#     row_prod = prod((1-t2.all_data.LESSER_SPOTTED_WOODPECKER.loc[(s,r,k)]) *(1-t2.all_data.THREE_TOED_WOODPECKER.loc[(s,r,k)])*(1-t2.all_data.LONG_TAILED_TIT.loc[(s,r,k)])* t2.model1.X1[(s,r)] for (s,r) in t2.model1.index1 for k in t2.model1.year)\n",
    "#     return t2.model1.HSI <= (1 - row_prod)\n",
    "# # t2.model1.COMB_HSI = Constraint(t2.model1.stands, rule=COMBINED_HSI)\n",
    "\n",
    "# #JUL:A function that evaluates the combined HSI\n",
    "# t2.model1.HSI=Var(within=NonNegativeReals, bounds=(0,1))\n",
    "# def COMBINED_HSI(model1,s):\n",
    "#     # Define a list of species name\n",
    "#     species_name = ['LESSER_SPOTTED_WOODPECKER', 'THREE_TOED_WOODPECKER']\n",
    "#     row_prod=[]\n",
    "#     for species in species_name:\n",
    "#         product = (1-t2.all_data[species].loc[(s,r,k)]* t2.model1.X1[(s,r)] for (s,r) in t2.model1.index1 for k in t2.model1.year)\n",
    "#         row_prod.append(product)\n",
    "#     final_product=prod(row_prod)\n",
    "#     return t2.model1.HSI <= (1 - final_product)\n",
    "# t2.model1.COMB_HSI = Constraint(t2.model1.stands, rule=COMBINED_HSI)\n",
    "\n",
    "#JUL:Constraint increasing HSI:\n",
    "def HSI_rule(model1, s):\n",
    "    HSI_k = t2.all_data.HSI.loc[(s, r, k)] * t2.model1.X1[(s, r)]\n",
    "    HSI_k_plus_1 = t2.all_data.HSI.loc[(s, r, k+1)] * t2.model1.X1[(s, r)]\n",
    "    return HSI_k_plus_1 >= HSI_k\n",
    "#t2.model1.HSI_limit = Constraint(t2.model1.stands, rule=HSI_rule)\n",
    "\n",
    "\n",
    "#Likely not needed -- used if constraints for even flow are present, and tries to remove them.\n",
    "try:\n",
    "    t2.model1.del_component(t2.model1.EVEN_inc)\n",
    "    t2.model1.del_component(t2.model1.EF)\n",
    "except:\n",
    "    print(\"NONE\")\n",
    "\n",
    "#Objective function -- maximizing NPV    \n",
    "def outcome_rule(model1):\n",
    "    return t2.model1.NPV #+t2.model1.HSI\n",
    "t2.model1.OBJ = Objective(rule=outcome_rule, sense=maximize)\n",
    "\n",
    "# Solve the modified optimization model\n",
    "t2.solve()\n",
    "\n",
    "#Function to extract decision variables from the optimized model\n",
    "def GET_DECISION_DATA():\n",
    "        st = []\n",
    "        reg = []\n",
    "        vals = []\n",
    "        for (s,r) in t2.model1.index1:\n",
    "            st = st+[s]\n",
    "            reg = reg+[r] \n",
    "            vals = vals+[t2.model1.X1[(s,r)].value]\n",
    "        data = {\"id\":st,\"branch\":reg,\"value\":vals}\n",
    "        df= pd.DataFrame(data)\n",
    "        df = df.set_index(['id','branch'])\n",
    "        return df\n",
    "\n",
    "# Extract decision data and merge with original dataset    \n",
    "dec  = GET_DECISION_DATA()\n",
    "merged_df = dec.merge(t2.all_data, left_index=True, right_index=True, how='left')\n",
    "\n",
    "# Save results to a CSV file\n",
    "merged_df.to_csv(path+\"output2d.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77a38687",
   "metadata": {},
   "outputs": [],
   "source": [
    "#JUL:A function that evaluates the combined HSI\n",
    "t2.model1.HSI=Var(t2.model1.stands, t2.model1.year, within=NonNegativeReals)#, bounds=(0,1))\n",
    "def COMBINED_HSI(model1, s, k):\n",
    "    ttw = (1- sum(t2.model1.X1[(s,r)] * t2.all_data.THREE_TOED_WOODPECKER.loc[(s,r,k)] for r in [x[1] for x in t2.model1.index1 if x[0] == s]))\n",
    "    ltt = (1- sum(t2.model1.X1[(s,r)] * t2.all_data.LONG_TAILED_TIT.loc[(s,r,k)] for r in [x[1] for x in t2.model1.index1 if x[0] == s]))\n",
    "    lsw = (1- sum(t2.model1.X1[(s,r)] * t2.all_data.LESSER_SPOTTED_WOODPECKER.loc[(s,r,k)] for r in [x[1] for x in t2.model1.index1 if x[0] == s]))\n",
    "    birds=1-ttw*ltt*lsw\n",
    "    return t2.model1.HSI[(s,k)] <= birds\n",
    "t2.model1.COMB_HSI = Constraint(t2.model1.stands,t2.model1.year, rule=COMBINED_HSI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5a1ff49",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2.model1.Landscape_HSI=Var(t2.model1.year, within=NonNegativeReals)#, bounds=(0,1))\n",
    "def Landscape_HSI(model1, k):\n",
    "    Land_HSI = sum(t2.model1.HSI[(s,k)] for s in t2.model1.stands)\n",
    "    return t2.model1.Landscape_HSI[k] <= Land_HSI\n",
    "t2.model1.COMB_LAND_HSI = Constraint(t2.model1.year, rule=Landscape_HSI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3b8542",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if hasattr(t2.model1, 'COMB_HSIx1'):\n",
    "#del t2.model1.COMB_HSIx1\n",
    "\n",
    "def COMBINED_HSI(model1, s, k):\n",
    "    ttw = (1 - sum(t2.model1.X1[(s, r)] * t2.all_data.THREE_TOED_WOODPECKER.loc[(s, r, k,0)] for r in [x[1] for x in t2.model1.index1 if x[0] == s]))\n",
    "    ltt = (1 - sum(t2.model1.X1[(s, r)] * t2.all_data.LONG_TAILED_TIT.loc[(s, r, k,0)] for r in [x[1] for x in t2.model1.index1 if x[0] == s]))\n",
    "    lsw = (1 - sum(t2.model1.X1[(s, r)] * t2.all_data.LESSER_SPOTTED_WOODPECKER.loc[(s, r, k,0)] for r in [x[1] for x in t2.model1.index1 if x[0] == s]))\n",
    "    birds = 1 - ttw * ltt * lsw\n",
    "    return t2.model1.HSIx1[(s, k)] == birds\n",
    "\n",
    "t2.model1.COMB_HSIx3 = Constraint(t2.model1.stands, t2.model1.year, rule=COMBINED_HSI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629bc1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test to define the combined HSI for 3 species\n",
    "#k = 2036\n",
    "#s=1025\n",
    "\n",
    "ttw = (1- sum(t2.model1.X1[(s,r)].value * t2.all_data.THREE_TOED_WOODPECKER.loc[(s,r,k,0)] for r in [x[1] for x in t2.model1.index1 if x[0] == s]))# *(1-(t2.all_data.THREE_TOED_WOODPECKER.loc[(s,r,k)]* t2.model1.X1[(s,r)].value for r in t2.model1.regimes)) *(1-(t2.all_data.LONG_TAILED_TIT.loc[(s,r,k)]* t2.model1.X1[(s,r)].value for r in t2.model1.regimes)))\n",
    "ltt = (1- sum(t2.model1.X1[(s,r)].value * t2.all_data.LONG_TAILED_TIT.loc[(s,r,k,0)] for r in [x[1] for x in t2.model1.index1 if x[0] == s]))\n",
    "lsw = (1- sum(t2.model1.X1[(s,r)].value * t2.all_data.LESSER_SPOTTED_WOODPECKER.loc[(s,r,k,0)] for r in [x[1] for x in t2.model1.index1 if x[0] == s]))\n",
    "birds=1-ttw*ltt*lsw\n",
    "birds\n",
    "print(birds, ltt,ttw,lsw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f00a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2.all_data.THREE_TOED_WOODPECKER.loc[(1024,0,2016,0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107fdcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRICKS\n",
    "# Create an instance of the optimization class\n",
    "optimizer = optimization()\n",
    "\n",
    "#to see the data frames\n",
    "all_data_new=optimizer.all_data\n",
    "merged_df_new=merged_df\n",
    "\n",
    "#to see the stands\n",
    "t2.model1.stands.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaea83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Landscape combined HSI\n",
    "#t2.model1.HSIx=Var(t2.model1.stands, t2.model1.year, within=NonNegativeReals, bounds=(0,1))\n",
    "def LAND_COMB_HSI(model1,k):\n",
    "    return sum(t2.model1.HSIx[s,k] for s in t2.model1.stands) >= sum(t2.model1.HSIx[s,k-1] for s in t2.model1.stands)\n",
    "t2.model1.LAND_COMB_HSIx = Constraint([x for x in t2.model1.year.data() if x != 2016], rule=LAND_COMB_HSI)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
